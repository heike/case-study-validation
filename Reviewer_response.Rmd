---
title: "Response"
author: "Susan Vanderplas"
date: "12/6/2019"
output: html_document
---

We thank the reviewer for his or her careful and constructive comments on our article, which we have retitled "Comparison of three similarity scores for bullet LEA matching". We have made several changes to the document in response to the suggestions made by the reviewer, and have responses to the comments which could not be easily addressed in this paper as it stands. 

The figures have been adjusted to have a larger font size for labels and titles; the caption size is set by the LaTeX template and is thus not easily editable by the authors. We expect that the captions will be sized appropriately in the final product; at the moment, we do not have control over the sizing of the figure captions. 

The choice to exclude score-based likelihood ratios was a conscious choice because the land-to-land comparisons result in density estimates with different variability between known matches and known non-matches. As a result, in these cases, the SLR is nonmonotonic and produces unexpected and potentially misleading results at the extremes of the distribution. As a result, we would like to defer the explicit use of SLRs in this paper; we have added a paragraph on the potential of using likelihood ratios with the scoring methods described in the paper. The threshold-based model we used in this paper is more consistent with the model used by examiners in our jurisdiction: decisions include, broadly, identification (the bullets match), exclusion (the bullets do not match), inconclusive, and insufficient evidence to make a conclusion. Our computational model does not require the last two categories, reducing this problem to a binary decision with a single threshold. We would also note that using likelihood ratios does not remove the need for a threshold; rather, it moves (implicitly or explicitly) to a threshold of 1, or 10, or whatever the criteria for "enough evidence" is set to.

The reviewer suggests using multiplication to combine land-to-land SLRs into a bullet-to-bullet SLR; we cannot recommend this course of action in part because the land to land scores are not independent, rather, they result from pairwise comparisons that are inherently dependent. Further, we can't assume that striae observed on different lands from the same physical bullet are independent, because they were all part of the same firing event. While this assumption is often made for practical purposes, the assumption is highly suspect and should not be further promoted without considering the covariance structures within the data. For this reason, we feel that the use of the sequence average match method for combining scores is more reasonable because it accounts for the spatial relationships between the set of lands belonging to the same bullet, without requiring assumptions of independence.

We appreciate the reviewer's discussion about the Ruger vs. non-Ruger bullets; we have included some of the suggestions in the paper, but do not currently have sufficient data to include a fourth case study in this paper. We agree that this would be an interesting test of the random forest score compared to the cross correlation and are planning several future studies which explore the random forest score's use on non-Ruger bullets. As this paper is already fairly lengthy, as noted by the reviewer, we feel that the addition of a non-Ruger case study is best reserved for one of these future papers. In addition, the Houston FSI study was also used to conduct examiner studies; we are preparing a paper which compares the algorithm's performance using the decision criteria shown in this paper to the performance of firearm examiners and expect to submit this paper for review in mid 2020. 

The final broad XXX comment addresses the matching of partial signatures, specifically suggesting that these signatures should be compared to a reference distribution assembled from partial signature comparisons. Hare, Hofmann, and Carriquiry (2017) showed how to use the random forest score to match degraded and partial land impressions; the random forest score remained fairly stable up to 50% signature length, suggesting that the random forest score, at least, is relatively robust to degradation and partial mark size. For the reasons stated above, we do not carry this conclusion all the way to the calculation of SLRs, but given the previously cited paper, we do not expect to require a separate comparison distribution when the partial LEA includes at least 50% of the area. 

We are also working on gaining approval to publish a data in brief paper with the data used in this paper, so that we can make the land scans publicly available for additional analysis; we strongly agree with the reviewer that the community would benefit from access to these scans. Two of the three sets have been uploaded to NBTRD at a lower resolution than the resolution used in our calculations. 

We have addressed many of the other minor comments, adding clarifications to address the specific issues with phrasing and technical corrections. We created a replacement for Figure 1 with the signatures overlaid, but found it difficult to read because the sequences are not (at this point in the algorithm) aligned, so much of the similarity is difficult to see when the unaligned details are overlaid. We include the modified Figure 1 here as a demonstration, but ultimately feel that the original Fig 1 (with labels of increased size) allows for easier visual comparison of the peaks in the sequence.

![](fig1-alt.png)

More specifically, we have addressed the corrections to the abstract, the phrasing of match strength vs. similarity, ambiguous terms such as stable crosscut, and the definition of stability. We appreciate these corrections, and hope that this revised manuscript is more clear. % need to talk through cutoff, imaging, training, peak/valley detection.